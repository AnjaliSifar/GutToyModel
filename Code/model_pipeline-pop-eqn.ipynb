{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "orig_nbformat": 2,
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.7.3 64-bit ('base': conda)"
    },
    "colab": {
      "name": "serendipity-pipeline.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "V_nTSdMXWgMV",
        "oJIp0Q7-W0dY"
      ],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "171b8712bf02bf9c30074648b83b9be1182d95d56d650742018a2c7e5290d606"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AnjaliSifar/GutToyModel/blob/main/serendipity_pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EivEUxP-XXLq"
      },
      "source": [
        "# **Generic code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZiHrcf9h0nZf",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from itertools import product\n",
        "import random\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "\n",
        "from datetime import datetime\n",
        "import os,errno"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxnitihqPdl8",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def createDir(dir):\n",
        "  try:\n",
        "      os.mkdir(dir)\n",
        "      print(\"created directory\",dir)\n",
        "  except OSError as e:\n",
        "      if e.errno == errno.EEXIST:\n",
        "          print('Directory ',dir,'already exists.')\n",
        "      else:\n",
        "          raise  "
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IuGXft_0nZt",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def writeParameters():\n",
        "  if saveFig:\n",
        "    now = datetime.now()\n",
        "    dt_string = now.strftime(\"%d/%m/%Y %H:%M:%S\")\n",
        "\n",
        "    createDir(folder)\n",
        "    \n",
        "    params = \"\"\" \n",
        "    =======================================================================================================================\n",
        "    SIMULATION RAN ON : {dt}\n",
        "    =======================================================================================================================\n",
        "    general comments = {comm}\n",
        "    number of iterations = {0}\n",
        "    step size, history recorded at every step size  = {1}\n",
        "    \n",
        "        \n",
        "    plot selection variables : choice = {ps1}, number of data points for representation = {ps2}\n",
        "    in case of a random slice of history:start = {ps3}, stop = {ps4}, step = {ps5}\n",
        "\n",
        "    BEHAVIOUR PARAMETERS \n",
        "    ---------------------\n",
        "    # nutrients = {b1}\n",
        "    state slicer = {b2}\n",
        "    action slicer = {b3}\n",
        "    shapes of stm, state space, action space = {b4},{b5},{b6}\n",
        "\n",
        "\n",
        "    GUT PARAMETERS\n",
        "    ----------------\n",
        "    Growth constant = {g1}\n",
        "    Decay constant = {g2}\n",
        "    K = {g3}\n",
        "    per bacteria contribution = {g4}\n",
        "\n",
        "    BRAIN PARAMETERS\n",
        "    ------------------\n",
        "    alpha = {bb1}\n",
        "    gamma = {bb2}\n",
        "    epsilon = {bb3}\n",
        "\n",
        "    \"\"\".format(iterations,stepSize\n",
        "    ,b1 = behavior.nNutrients,b2 = behavior.stateSlicer,b3 = behavior.actionSlicer\n",
        "    ,b4 = behavior.stm.shape,b5 = len(behavior.stateSet),b6 = len(behavior.actionSet)\n",
        "    ,b7 = behavior.stateSet,b8 = behavior.actionSet\n",
        "    ,g1 = gut.gc,g2 = gut.dc,g3 = gut.K,g4 = gut.contribution\n",
        "    ,bb1 = brain.alpha,bb2 = brain.gamma, bb3 = brain.epsilon\n",
        "    ,ps1 = choice, ps2 = plotDataPoints, ps3 = start, ps4 = stop, ps5 = step\n",
        "    ,dt = dt_string\n",
        "    ,comm = comments\n",
        "    )\n",
        "\n",
        "    with open(folder+\"parameters.txt\", \"a\") as file:\n",
        "        file.write(params)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "sR7v2hmji4Lt"
      },
      "source": [
        "#@title\n",
        "def generatePlotSel(choice = 'random',**kwargs):\n",
        "    sel = np.arange(5)\n",
        "    if choice == 'random':\n",
        "        n = kwargs.get('n',5)\n",
        "        randSel = np.random.randint(0,iterations,n)\n",
        "        randSel.sort()\n",
        "        sel =  randSel\n",
        "    elif choice == 'all':\n",
        "        sel = np.arange(iterations)\n",
        "    elif choice == 'custom':\n",
        "        start = kwargs.get('start',0)\n",
        "        stop = kwargs.get('stop',5)\n",
        "        step = kwargs.get('step',1)\n",
        "        sel = np.arange(start,stop,step)\n",
        "    \n",
        "    else:\n",
        "        print(\"first five selection only.\")\n",
        "    return sel\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAdLqw1NXhMX"
      },
      "source": [
        "# **System**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "67dahBXa0nZj",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "   \n",
        "class Brain:\n",
        "    def __init__(self, behavior, **kwargs):\n",
        "\n",
        "        # Params\n",
        "        self.alpha = kwargs.get('alpha', 0.1)\n",
        "        self.gamma = kwargs.get('gamma', 0.05)\n",
        "        self.epsilon = kwargs.get('epsilon', 0.1)\n",
        "        \n",
        "        self.time = kwargs.get('time', 1)  #for debugging\n",
        "\n",
        "        # for convenience\n",
        "        self.nActions = len(behavior.actionSet)\n",
        "        self.nStates = len(behavior.stateSet)\n",
        "\n",
        "        # To be computed\n",
        "        self.qTable = np.zeros((self.nStates,self.nActions))\n",
        "        self.oStateInd = behavior.stateInd\n",
        "        self.oActionInd = None\n",
        "\n",
        "\n",
        "    def do(self,stateInd):\n",
        "        self.oStateInd= stateInd\n",
        "        if(np.random.random() > self.epsilon):\n",
        "            actionInd = self.exploit(stateInd)\n",
        "        else:\n",
        "            actionInd = self.explore()\n",
        "\n",
        "        self.oActionInd = actionInd\n",
        "        return self.oActionInd\n",
        "\n",
        "        \n",
        "\n",
        "    def learn(self,newstate, reward):\n",
        "        \n",
        "        old_q = self.qTable[self.oStateInd,self.oActionInd]\n",
        "        maxFutureQ = max(self.qTable[newstate, :])\n",
        "\n",
        "        self.qTable[self.oStateInd, self.oActionInd] = old_q + self.alpha*(reward +                 self.gamma*maxFutureQ - old_q)\n",
        "\n",
        "# For debugging only\n",
        "        # delta = self.qTable[self.oStateInd, self.oActionInd] - old_q\n",
        "        # if self.time%100 == 0:\n",
        "        #     print(\"\"\" delta = {0:.4f} , old q= {1:.3f}, new q = {2:.3f}\n",
        "        #         \"\"\".format(delta,old_q,self.qTable[self.oldStateIndex, self.oldActionIndex]))\n",
        "\n",
        "        \n",
        "           \n",
        "    def exploit(self,stateInd):\n",
        "        possibleActionValues = self.qTable[stateInd, :]\n",
        "        maxActionInd = np.where(possibleActionValues == max(possibleActionValues))[0]\n",
        "        return np.random.choice(maxActionInd)\n",
        "        \n",
        "        \n",
        "    def explore(self):\n",
        "        return np.random.choice(range(self.nActions))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "S9WO0fiJ0nZl",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "class Behavior:\n",
        "    def __init__(self,initState=None,nNutrients = 3, **kwargs):\n",
        "\n",
        "\n",
        "        self.nNutrients = nNutrients\n",
        "\n",
        "# Create state and action sets\n",
        "        self.stateSlicer =  kwargs.get('stateSlicer',5)\n",
        "        self.actionSlicer =  kwargs.get('actionSlicer', 2)\n",
        "\n",
        "        tempState = np.linspace(0, 1, self.stateSlicer).round(2)\n",
        "        #to include space for each nutrient, dynamically add state space for each nutrient\n",
        "        tempList = np.tile(tempState,(nNutrients,1)) \n",
        "        self.stateSet = list(product(*tempList)) \n",
        "        \n",
        "        temp_t = tempState[1]-tempState[0]\n",
        "        tempAction = np.linspace(-temp_t,temp_t,self.actionSlicer)\n",
        "        tempList = np.tile(tempAction,(nNutrients,1)) \n",
        "        self.actionSet = list(product(*tempList))\n",
        "\n",
        "\n",
        "        if not initState:\n",
        "            self.stateInd = np.random.choice(range(len(self.stateSet)))\n",
        "            print(\"\"\"randomly initialised to {0} state\"\"\".format(self.stateSet[self.stateInd]))\n",
        "        else:\n",
        "            state =  initState   #Initializing\n",
        "            self.stateInd = self.findStateIndex(state)\n",
        "            print(\"\"\"initialised to  {0}\"\"\".format(state))\n",
        "\n",
        "\n",
        "        self.stm = np.zeros((len(self.stateSet), len(self.actionSet)))\n",
        "        self.computeStateTransitions()\n",
        "\n",
        "\n",
        "        self.output = np.zeros((self.nNutrients))\n",
        "\n",
        "\n",
        "    def computeStateTransitions(self):\n",
        "        tic = time.perf_counter()\n",
        "\n",
        "        for (si,_),(ai,_) in product(enumerate(self.stateSet),enumerate(self.actionSet)):\n",
        "            nsi = self.updateState(si,ai) \n",
        "            self.stm[si,ai] = nsi\n",
        "        toc = time.perf_counter()\n",
        "\n",
        "        print(\"\"\"total time to compute state transition matrix = {0:.2f} seconds\"\"\".format(toc-tic))\n",
        "\n",
        "\n",
        "    def findStateIndex(self,s):\n",
        "        return np.where((self.stateSet == s).all(axis=1))[0][0]           \n",
        "\n",
        "\n",
        "    def updateState(self,si,ai):\n",
        "        s = self.stateSet[si]\n",
        "        a = self.actionSet[ai]\n",
        "        #new state defined by behavior based upon action chosen by brain\n",
        "        ns = np.clip(np.array(s)+np.array(a),0,1).round(2) \n",
        "        ind = self.findStateIndex(ns)\n",
        "        return ind\n",
        "\n",
        "    def ingestNutrients(self):\n",
        "        self.output = np.random.binomial(1,self.stateSet[self.stateInd])\n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YBoOoEq0nZo",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "class Gut:\n",
        "    def __init__(self,initPop = None,nBacteria = 3,**kwargs):\n",
        "        \n",
        "\n",
        "        self.nBacteria = nBacteria\n",
        "        self.pop = np.random.choice(np.arange(100,200),self.nBacteria)\n",
        "        self.init_pop = self.pop\n",
        "        self.gc = np.repeat([kwargs.get('gc',0.1)],nb)\n",
        "        self.dc = np.repeat([kwargs.get('dc',0.1)],nb)\n",
        "        self.K = kwargs.get('K',25000)\n",
        "        self.contribution = kwargs.get('contribution',np.ones((nBacteria)))\n",
        "            \n",
        "    ## Population-based implementation\n",
        "    def updatePopulation(self, nutrients):\n",
        "        self.pop = self.pop*(1 + self.gc*nutrients*(1- np.sum(self.pop)/self.K) - self.dc*(self.nBacteria*self.pop/self.K))\n",
        "\n",
        "\n",
        "\n",
        "    def generateReward(self,nutrients):\n",
        "\n",
        "        self.reward = np.sum(self.pop*self.contribution*nutrients)\n",
        "        self.reward = self.reward/(self.gc*self.K/self.dc)\n",
        "    "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_nTSdMXWgMV"
      },
      "source": [
        "# configure before running the simulation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eNreFjUbjCys"
      },
      "source": [
        "setup the next cell only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KfVwnPXHjHQV",
        "outputId": "5b7ddc3e-4fa0-4d25-a075-cc9549f964e6"
      },
      "source": [
        "destination = 'others'\n",
        "\n",
        "if destination == 'drive':\n",
        "    # run the below code if running in Colab and you wish to save file in the drive.\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/gdrive')\n",
        "  base_dir = '/content/gdrive/MyDrive/Colab Notebooks/'\n",
        "else:\n",
        "  base_dir = '../simulations/'\n",
        "base_dir = base_dir + 'simulations-21June/'\n",
        "createDir(base_dir)\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  ../simulations/simulations-21June/ already exists.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJIp0Q7-W0dY"
      },
      "source": [
        "# **Plots below**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNC0JckA0nZu",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def plotPopulation():\n",
        "    # one scatter plot for each bacterium population. \n",
        "    # relevant to trace out the population evolution across timesteps.\n",
        "\n",
        "    X = np.arange(sel.size)\n",
        "    fig,ax = plt.subplots(nrows,ncols,sharex = True, sharey = True,figsize = (15,6))\n",
        "    cm = plt.get_cmap(\"tab10\")\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    for i in range(gut.nBacteria):\n",
        "      ax[i].scatter(X,gutPopHistory[sel,i],color = cm(i))\n",
        "      ax[i].set_ylabel(\"gut population\")\n",
        "      ax[i].set_xlabel(\"time\")\n",
        "      ax[i].set_title(\"\"\" total = {4:.0f}\n",
        "      contri={0}, prob = {3:.2f}\n",
        "      initial, final pop = {1}, {2:.0f}\"\"\".format(gut.contribution[i], gut.init_pop[i], gut.pop[i],stateHistory[:,i].mean(),gut.pop.sum()))\n",
        "\n",
        "    # fig.text(0.4,0.9,\"Individual gut bacteria population evolution\")\n",
        "    if saveFig:\n",
        "      plt.savefig(folder+'scatter-per-bact-pop'+str(counter+1),bbox_inches = 'tight',format= fileFormat)\n",
        "    plt.close()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O14e6ncO0nZv",
        "cellView": "form"
      },
      "source": [
        "  def plotState():\n",
        "    #@title\n",
        "    # one scatter plot for state history. \n",
        "    # relevant to trace out the population evolution across timesteps.\n",
        "\n",
        "\n",
        "    X = np.arange(sel.size)\n",
        "    fig,ax = plt.subplots(nrows,ncols,sharex = True, sharey = True,figsize = (15,6))\n",
        "    cm = plt.get_cmap(\"tab10\")\n",
        "    ax = ax.ravel()\n",
        "\n",
        "    for i in range(gut.nBacteria):\n",
        "      ax[i].scatter(X,stateHistory[sel,i],color = cm(i))\n",
        "      ax[i].set_ylabel(\"cravings\")\n",
        "      ax[i].set_xlabel(\"time\")\n",
        "      ax[i].set_title(\"\"\"probability of nutrients = {0:.2f}\n",
        "      \"\"\".format(stateHistory[:,i].mean()))\n",
        "\n",
        "    # fig.text(0.4,0.9,\"Individual state history\")\n",
        "    if saveFig:\n",
        "      plt.savefig(folder+'scatter-state'+str(counter+1),bbox_inches = 'tight',format= fileFormat)    \n",
        "    plt.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyXDJ9090nZy",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def plotReward():\n",
        "\n",
        "  # plotting reward history\n",
        "  plt.scatter(range(sel.size),rewardHistory[sel])\n",
        "  plt.xlabel(\"time\")\n",
        "  plt.ylabel(\"normalized reward\")\n",
        "  if saveFig:\n",
        "    plt.savefig(folder+'reward'+str(counter+1),bbox_inches = 'tight',format= fileFormat)\n",
        "  plt.close()        "
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-x7xSCNB0nZx",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "def plotBehavior():\n",
        "  # Behavior history for each bacterium - whether the bacteria received the nutrient or not. \n",
        "  # yellow represents higher values (or presence of nutrient to the bacteria)\n",
        "  # width of heat map = \n",
        "  # nrow = 2; ncol = gut.nBacteria//nrow\n",
        "\n",
        "  a = behaviorHistory\n",
        "  height = int(0.9*len(behavior.stateSet)//len(behavior.actionSet)) #height of the heat map\n",
        "  # height = int(len(behavior.stateSet)//2)\n",
        "  fig,ax = plt.subplots(nrows,ncols,sharey = True,sharex = True,figsize = (50,50))\n",
        "  ax = ax.ravel()\n",
        "\n",
        "  for i in range(gut.nBacteria):\n",
        "    # ax[i].imshow(np.tile(a[plotN:,i],(height,1)))\n",
        "    ax[i].imshow(np.tile(a[sel,i],(height,1)))\n",
        "    ax[i].set_xticklabels([])\n",
        "    ax[i].set_yticklabels([])\n",
        "    ax[i].set_title(\"nutrient \"+str(i+1))\n",
        "  fig.text(0.3,0.3,\"time steps (whether with time, nutrients were being ingested or not?)\")\n",
        "  if saveFig:\n",
        "    plt.savefig(folder+'nutrient-behavior'+str(counter+1),bbox_inches = 'tight',format= fileFormat)\n",
        "  plt.close()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1EKMSyN60nZw",
        "cellView": "form"
      },
      "source": [
        "#@title\n",
        "#heat map\n",
        "def plotQTable():\n",
        "    nstates = len(behavior.stateSet)\n",
        "    nactions = len(behavior.actionSet)\n",
        "    expansion = 0.5*nstates//nactions\n",
        "\n",
        "\n",
        "    actions = behavior.actionSet\n",
        "    states = [behavior.stateSet[int(i)] for i in np.linspace(0,nstates,behavior.stateSlicer+1)[:-1]]\n",
        "\n",
        "    fig,ax = plt.subplots(1,1,figsize = (20,20))\n",
        "    ax.imshow(np.repeat(brain.qTable,expansion,1))\n",
        "\n",
        "    ax.set_xticks(np.linspace(0,nactions*expansion-1,nactions+1))\n",
        "    ax.set_xticklabels(actions,rotation = 45,fontsize = 6)\n",
        "\n",
        "    ax.set_yticks(np.linspace(0,nstates,behavior.stateSlicer+1))\n",
        "    ax.set_yticklabels(states,rotation = 90,fontsize = 6)\n",
        "\n",
        "    ax.set_xlabel(\"actions\")\n",
        "    ax.set_ylabel(\"states\")\n",
        "\n",
        "    if saveFig:\n",
        "      plt.savefig(folder+'qtable'+str(counter+1),bbox_inches = 'tight',format = fileFormat)\n",
        "    plt.close()        "
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "SZ62P16Std1Q"
      },
      "source": [
        "#@title\n",
        "def plotActionHistory():\n",
        "  plt.clf()\n",
        "  # plot action history to check the stagnation towards the end\n",
        "\n",
        "  X = np.arange(sel.size)\n",
        "\n",
        "  fig,ax = plt.subplots(1,1,sharex = True, sharey = True,figsize = (15,6))\n",
        "  cm = plt.get_cmap(\"tab10\")\n",
        "\n",
        "  act_ind = []\n",
        "  actions = behavior.actionSet\n",
        "  for a in actionHistory[sel]:\n",
        "    act_ind.append(np.where((a == actions).all(1))[0][0])\n",
        "\n",
        "\n",
        "  plt.scatter(X,act_ind,c = np.tile(range(20),len(X)//20),cmap = plt.get_cmap())\n",
        "  plt.ylabel(\"Action\")\n",
        "  plt.xlabel(\"Time\")\n",
        "  plt.colorbar()\n",
        "  plt.yticks(range(len(actions)),actions) \n",
        "  fig.text(0.5,0.9,\"Action History\")\n",
        "\n",
        "  if saveFig:\n",
        "    plt.savefig(folder+'action-history'+str(counter+1)+'.'+fileFormat,bbox_inches = 'tight',format= fileFormat)\n",
        "  plt.close()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4ohc893uVMK"
      },
      "source": [
        "<!-- running same simulation multiple times for different configurations -->"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vu2SjPFGu1F5"
      },
      "source": [
        "# for pipeline with configurations only"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rJrkS4PuhYH",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "0b65bc62-066c-46a0-df78-72c318aeb331"
      },
      "source": [
        "# %%capture out\n",
        "#@title\n",
        "\n",
        "nruns = 1\n",
        "nExps = 2\n",
        "\n",
        "#experimental conditions change here. \n",
        "from itertools import product as pr\n",
        "gc = np.array([0.01,0.02,0.1])\n",
        "dc = np.array([0.01,0.02,0.1])\n",
        "nb = np.array([3,4])\n",
        "alpha = np.array([0.05,0.1,0.2])\n",
        "gamma = np.array([0.01,0.05,0.1])\n",
        "contri_index = np.array([0,1,2])\n",
        "expVars = np.array(list(pr(nb,gc,dc,contri_index)))\n",
        "\n",
        "contributions = np.array([\n",
        "       [1, 1, 1, 1],\n",
        "       [0, 1, 0, 1],\n",
        "       [-1, 0, 1, 0]\n",
        "       ])\n",
        "\n",
        "\n",
        "comments = \"Same initial state of the behavior is used for each run of the experiment. In general, a different exploration decay is used in different experiments \"\n",
        "\n",
        "for exp in range(nExps):\n",
        "  #change these for every experiment \n",
        "  folder = base_dir+'exp-'+str(exp+1)+'/' \n",
        "  saveFig = True\n",
        "  fileFormat ='png'\n",
        "\n",
        "  nb = int(expVars[exp,0])\n",
        "  behavior = Behavior(nNutrients=nb,stateSlicer = 6,actionSlicer = 2)\n",
        "\n",
        "\n",
        "  for counter in range(nruns):\n",
        "    brain = Brain(behavior)\n",
        "    gut = Gut(nBacteria = nb)\n",
        "\n",
        "    gut.gc = expVars[exp,1]\n",
        "    gut.dc = expVars[exp,2]\n",
        "    gut.contribution = contributions[int(expVars[exp,3]),:nb]\n",
        "    epsilon_mod = 3000\n",
        "\n",
        "    nrows = 2 if gut.nBacteria>3 else 1 #change this according to number of nutrients\n",
        "    ncols = gut.nBacteria//nrows \n",
        "\n",
        "    stepSize = 1\n",
        "    iterations = 500\n",
        "    n = iterations//stepSize\n",
        "\n",
        "    # below parameters to pick appropriate data points for plotting only.\n",
        "    choice = 'random'\n",
        "    plotDataPoints = 500\n",
        "    start,stop,step = 0,5,1\n",
        "    sel = generatePlotSel(choice,n = plotDataPoints,iterations = iterations)  #check code definition to send proper variables\n",
        "\n",
        "\n",
        "    behaviorHistory = np.zeros((iterations//stepSize,behavior.nNutrients))\n",
        "    gutPopHistory = np.zeros((iterations//stepSize,gut.nBacteria))\n",
        "    rewardHistory = np.zeros((iterations//stepSize))\n",
        "    stateHistory = np.zeros((iterations//stepSize,behavior.nNutrients))\n",
        "    actionHistory = np.zeros((iterations//stepSize,behavior.nNutrients))\n",
        "    idx=0\n",
        "    for t in tqdm(range(iterations)):\n",
        "        \n",
        "\n",
        "        # find best possible action in brain using RL\n",
        "        actionInd = brain.do(behavior.stateInd)\n",
        "        \n",
        "        # update behavior state as a result of action chosen by brain\n",
        "        oldInd = behavior.stateInd\n",
        "        newStateInd = behavior.updateState(behavior.stateInd,actionInd)\n",
        "        behavior.stateInd = newStateInd\n",
        "\n",
        "        #find the reward elicited by gut\n",
        "        behavior.ingestNutrients()\n",
        "        gut.generateReward(behavior.output)\n",
        "        \n",
        "        gut.updatePopulation(behavior.output)\n",
        "        \n",
        "        brain.learn(newStateInd,gut.reward)\n",
        "        brain.time = t\n",
        "\n",
        "        if t%epsilon_mod ==0:\n",
        "            brain.epsilon*=0.99\n",
        "\n",
        "        if t%stepSize==0:\n",
        "            behaviorHistory[idx] = behavior.output\n",
        "            gutPopHistory[idx] = gut.pop\n",
        "            rewardHistory[idx] = gut.reward\n",
        "            stateHistory[idx] = behavior.stateSet[oldInd]\n",
        "            actionHistory[idx] = behavior.actionSet[actionInd]\n",
        "\n",
        "            idx+=1\n",
        "\n",
        "    writeParameters()\n",
        "\n",
        "  np.save(folder+'population-dynamics.npy',gutPopHistory)\n",
        "  np.save(folder+'state-dynamics.npy',stateHistory)\n",
        "\n",
        "\n",
        "    # plotPopulation()\n",
        "\n",
        "    # plotState()\n",
        "\n",
        "    # plotReward()\n",
        "\n",
        "    # plotBehavior()\n",
        "    \n",
        "    # plotQTable()\n",
        "\n",
        "    # plotActionHistory()\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "randomly initialised to (0.2, 0.0, 0.0) state\n",
            "100%|██████████| 500/500 [00:00<00:00, 3687.40it/s]total time to compute state transition matrix = 0.23 seconds\n",
            "Directory  ../simulations/simulations-21June/exp-1/ already exists.\n",
            "randomly initialised to (0.6, 0.2, 0.4) state\n",
            "\n",
            "100%|██████████| 500/500 [00:00<00:00, 2669.44it/s]total time to compute state transition matrix = 0.25 seconds\n",
            "Directory  ../simulations/simulations-21June/exp-2/ already exists.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}