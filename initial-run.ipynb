{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from itertools import product\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(product(np.linspace(0,1,11).round(1),np.linspace(0,1,11).round(1),np.linspace(0,1,11).round(1)))\n",
    "len(a),a\n",
    "rtable = {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dopamine_b1 = np.zeros(1331)\n",
    "for i,kk in enumerate(a):\n",
    "    dopamine_b1[i] = np.round(2*kk[0]+0.6*kk[1]+0.1*kk[2],2)\n",
    "\n",
    "dopamine_b2 = np.zeros(1331)\n",
    "for i,kk in enumerate(a):\n",
    "    dopamine_b2[i] = np.round(5*kk[0]+0.1*kk[1]+0.2*kk[2],2)\n",
    "    \n",
    "dopamine_b3 = np.zeros(1331)\n",
    "for i,kk in enumerate(a):\n",
    "    dopamine_b3[i] = np.round(1*kk[0]+0.1*kk[1]+0.01*kk[2],2)\n",
    "\n",
    "\n",
    "max_dop = np.zeros(len(a))\n",
    "\n",
    "for ii,ai in enumerate(a):\n",
    "    rtable[ai,'bacteria_1'] = dopamine_b1[ii]\n",
    "    rtable[ai,'bacteria_2'] = dopamine_b2[ii]\n",
    "    rtable[ai,'bacteria_3'] = dopamine_b3[ii]\n",
    "    max_dop[ii] = dopamine_b1[ii] +dopamine_b2[ii]+dopamine_b3[ii]\n",
    "\n",
    "    \n",
    "max(max_dop),max_dop[-1],max_dop"
   ]
  },
  {
   "source": [
    "## conversion of probabilities to population\n",
    "1. sampling distribution - extract quantities. One unit everytime.\n",
    "2. one to one mapping between nutrient and dopamine.\n",
    "3. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(array([0.04054308, 0.1192611 , 0.56899783]),\n",
       " (0.2, 0.9, 0.1),\n",
       " array([1, 1, 0]))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "nut_qty = np.random.random(3)\n",
    "nut_qty,a[342], nut_qty< np.array(a[342])\n",
    "craving_probability = a[342]\n",
    "nut_qty, a[342],(nut_qty < craving_probability)*1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b =(tuple(np.random.choice(np.linspace(0,1,11),3).round())),np.random.choice(['bacteria_1','bacteria_2','bacteria_3'])\n",
    "\n",
    "b,rtable.get(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 2])"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "np.array((0,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### observations\n",
    "1. When action can be nothing, it slowl\n",
    "\n",
    "3. Possible actions in one nutrient only includes 0.1 (say, a regular increase in the consumption of alcohol. The probability of consuming that nutrient becomes very high along with highest possible reward state; and potentially reducing the craving or eating probability of other nutrients especially (at least one of them).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bacteria():\n",
    "    def __init__(self,t):\n",
    "        self.population_size = np.random.randint(100,200)\n",
    "        self.type = t\n",
    "\n",
    "    def growPopulation(self):\n",
    "        self.population_size = self.population_size**2\n",
    "\n",
    "\n",
    "class Behavior():\n",
    "    def __init__(self,organism):\n",
    "        self.nutrients = (1,0.0,0.0)\n",
    "        self.organism = organism\n",
    "\n",
    "    def ingestNutrients(self):\n",
    "        temp = np.array(self.brain.state)\n",
    "        self.nutrients = np.random.random(temp.size) < temp\n",
    "        \n",
    "    def getIngestedNutrients(self):\n",
    "        return self.nutrients\n",
    "\n",
    "\n",
    "class Organism():\n",
    "    \n",
    "    def __init__(self,n):\n",
    "        # self.nutrients = n\n",
    "        self.brain = Brain(self)\n",
    "        self.gut = [Bacteria('bacteria_'+str(i+1)) for i in range(3)]\n",
    "        self.behavior = Behavior(self)\n",
    "        \n",
    "    def run(self):\n",
    "        self.brain.setInititalState()\n",
    "        for i in range(1000):\n",
    "            self.brain.takeAction()\n",
    "            self.behavior.ingestNutrients()\n",
    "            for j in range(3):\n",
    "                if self.behavior.nutrients[j]==1:\n",
    "                    self.gut[j].growPopulation()\n",
    "\n",
    "\n",
    "act = list(product(np.linspace(0,0.1,2),np.linspace(-0.1,0.1,2),np.linspace(-0.1,0.1,2)))\n",
    "# act.remove((0.0,0.0,0.0))\n",
    "act = tuple(act)\n",
    "\n",
    "    \n",
    "class Brain():\n",
    "    \n",
    "    def __init__(self,organism):\n",
    "        self.organism = organism\n",
    "#          check what to name this \n",
    "        self.actions = act\n",
    "        self.state = (0,0,1)\n",
    "        \n",
    "        self.alpha = 1\n",
    "        self.gamma = 0.1\n",
    "        self.epsilon = 0.01\n",
    "        self.qtable = {}\n",
    "\n",
    "    def setInititalState(self):\n",
    "        self.state = np.random.random(3)\n",
    "        print(\"starting with state or craving probabilities :\",self.state)\n",
    "\n",
    "    def takeAction(self):\n",
    "        all_q = [self.qtable.get((self.state,a),0.0) for a in self.actions]\n",
    "        all_max_ind = np.where(all_q == np.max(all_q))[0]\n",
    "        action = self.actions[np.random.choice(all_max_ind)]\n",
    "        \n",
    "#         use exploration\n",
    "        if np.random.random()< self.epsilon:\n",
    "            action = tuple(np.random.choice([0.1,0.0,-0.1], 3))\n",
    "            \n",
    "            \n",
    "        self.ostate = self.state\n",
    "        self.oaction = action\n",
    "        self.state = tuple(np.round(np.clip(np.array(self.ostate) + np.array(action),0,1),1))\n",
    "        \n",
    "\n",
    "        # this is the summation of dopamine from all bacterium, say         \n",
    "        self.oreward = np.sum([rtable.get((self.ostate,b.type)) for b in self.organism.gut])\n",
    "#         print(\"\"\" While selecting an action: \n",
    "#         old state = {0}\n",
    "#         action taken = {1}\n",
    "#         new state = {2}\n",
    "\n",
    "#         reward = {3}\n",
    "#         \"\"\".format(self.ostate, action,self.state,self.oreward,self.state))\n",
    "        \n",
    "        self.learn()\n",
    "        \n",
    "        \n",
    "    def learn(self):\n",
    "        old_q = self.qtable.get((self.ostate,self.oaction),0.0)\n",
    "#         print(\"\"\"\n",
    "#         old_q  = {0}\n",
    "#         self state = {4}, old state = {5}\n",
    "#         qtable = {3}\n",
    "#         \"\"\".format(old_q,len(self.actions),self.actions,\n",
    "#                   self.qtable.get((self.state,self.actions[0]),np.nan),\n",
    "#                    self.state,self.ostate))\n",
    "\n",
    "        max_new_q = np.max([self.qtable.get((self.state,a),0.0) for a in self.actions])\n",
    "        \n",
    "        \n",
    "        newq = old_q + self.alpha*(self.oreward + self.gamma*max_new_q - old_q)\n",
    "        \n",
    "        self.qtable[(self.ostate,self.oaction)] = np.round(newq,3)\n",
    "        \n",
    "        \n",
    "#         print(\"\"\"\n",
    "#                 Old Q = {0}\n",
    "#         max New Q = {1}\n",
    "#         New Q = {2}\n",
    "\n",
    "#         Q table = {3}\n",
    "#     \"\"\".format(old_q,max_new_q,newq,self.qtable))\n",
    "\n",
    "o = Organism((0.2,0.4,0.3))\n",
    "o.run()\n",
    "o.brain.qtable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "oo = OrderedDict(o.brain.qtable)\n",
    "oo.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = max(o.brain.qtable.values())\n",
    "\n",
    "\n",
    "[k for k,v in o.brain.qtable.items() if v == max_value],max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act = list(product(np.linspace(0,0.1,2),np.linspace(-0.1,0.1,2),np.linspace(-0.1,0.1,2)))\n",
    "# act.remove((0.0,0.0,0.0))\n",
    "act = tuple(act)\n",
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearn():\n",
    "    def __init__(self):\n",
    "        self.alpha = 0.2\n",
    "        self.gamma = 0.7\n",
    "        self.epsilon = 0.1\n",
    "        self.qtable = {}\n",
    "        self.agent = None\n",
    "        self.ostate = ()\n",
    "        self.oaction = 0\n",
    "        \n",
    "    def getState(self):\n",
    "        return self.agent.state\n",
    "        \n",
    "    def getBestAction(self):\n",
    "        all_q = [self.qtable.get((self.getState(),a),0.0) for a in self.agent.actions]\n",
    "        all_max_ind = np.where(all_q == np.max(all_q))[0]\n",
    "        action = self.agent.actions[np.random.choice(all_m_ind)]\n",
    "\n",
    "        print(f\"\"\"\n",
    "        possible q for all actions = {all_q}\n",
    "        index of all max = {all_max_ind}\n",
    "        action = {action_taken}\n",
    "        \"\"\")\n",
    "        \n",
    "        self.ostate = self.getState()\n",
    "        self.oaction = action\n",
    "        return action\n",
    "        \n",
    "    def learn(self):\n",
    "        old_q = self.qtable.get((self.ostate,self.oaction),0.0)\n",
    "        max_new_q = np.max([self.qtable.get((self.getState(),a),0.0) for a in self.agent.actions])\n",
    "\n",
    "        newq = old_q + self.alpha*(self.agent.reward + self.gamma*max_new_q - old_q)\n",
    "        self.qtable[(self.ostate,self.oaction)] = newq\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# global clock\n",
    "\n",
    "\n",
    "class Organism():\n",
    "    def __init__(self):\n",
    "        self.categories = ['a','b','c']        \n",
    "        self.gut = [Bacteria(c,self) for c in self.categories]\n",
    "#         self.eatingBehavior - somehow this shud reflect on different nutrients intake \n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Bacteria():\n",
    "#     def __init__(self,cat, org):\n",
    "#         self.category = cat\n",
    "#         self.organism = org\n",
    "#         self.population = np.random.randint(100,200)\n",
    "# #         self.chemical = output(cat)\n",
    "        \n",
    "#     def output(self,cat):\n",
    "#         chem = 0\n",
    "#         return chem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## breakdown of steps\n",
    "\n",
    "1. create a world (person) with 5 (5 is becoming unmanageable for this simple example) gut bacteria, and 5 nutrients?\n",
    "2. [x] mapping between nutrients and bacteria - and that between bacteria and chemicals. make a table for now. \n",
    "3. when we initialise the person, the hunger signal tells the person to eat - with some probability ..\n",
    "4. Nutrients get injected into the system - and once that is done, RL tells us what action to take .. \n",
    "    * state is identified with say, time of the day, gut bacterial population and thus, which will be reflected in the amount of dopamine that will come as a reward\n",
    "    * amount of dopamine (instead of just presence)can be used as the possible reward state. \n",
    "    * action is the increase/decrease in the probability of getting a certain type of nutrients. \n",
    "    * for this use case, we inject a major proportion of alcohol or sugar into the system.\n",
    "    * for now, we can also decide the initial composition of the nutrients and gut bacteria to test the use case in the most abstract form ?\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "d = defaultdict(dict)\n",
    "\n",
    "# this way is not extensible at all, but for the momemnt - just stick with it to develop a simple use case,\n",
    "\n",
    "d['carbs']['a'] = 0.1\n",
    "d['carbs']['b'] = 1\n",
    "d['carbs']['c'] = 0.2\n",
    "\n",
    "d['fats']['a'] = 0.1\n",
    "d['fats']['b'] = 1\n",
    "d['fats']['c'] = 0\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # use dictionary instead if dopamine remains constant and only that chemical brings in reward\n",
    "\n",
    "# a = [['carbs','a','dopamine',1],\n",
    "#      ['carbs','b','dopamine',3],\n",
    "#      ['carbs','c','dopamine',1],\n",
    "#      ['carbs','d','dopamine',0],\n",
    "#      ['carbs','e','dopamine',0],\n",
    "#      ['protein','a','dopamine',0],\n",
    "#      ['protein','b','dopamine',0],\n",
    "#      ['protein','c','dopamine',0],\n",
    "#      ['protein','d','dopamine',0],\n",
    "#      ['protein','e','dopamine',0],\n",
    "#      ['fats','a','dopamine',0],\n",
    "#      ['fats','b','dopamine',0],\n",
    "#      ['fats','c','dopamine',0]\n",
    "    \n",
    "    \n",
    "#     ]\n",
    "\n",
    "# tab = pd.DataFrame(columns = {'nutrients','bacterium','chemical','quantity'},index = range(len(a)))\n",
    "\n",
    "# for i,f in enumerate(a):\n",
    "#     tab.iloc[i] = a[i]\n",
    "    \n",
    "# tab\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}